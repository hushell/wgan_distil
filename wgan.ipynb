{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import numpy as np\n",
    "import math\n",
    "import sys\n",
    "#from tqdm import tqdm, tqdm_notebook\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.utils import save_image\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.autograd as autograd\n",
    "import torch\n",
    "import tensorboardX\n",
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(b1=0.5, b2=0.999, batch_size=64, channels=1, clip_value=0.01, gpu_id=2, img_size=28, latent_dim=100, lr=0.0002, n_cpu=8, n_critic=5, n_epochs=200, sample_interval=400)\n"
     ]
    }
   ],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument(\"--n_epochs\", type=int, default=200, help=\"number of epochs of training\")\n",
    "parser.add_argument(\"--batch_size\", type=int, default=64, help=\"size of the batches\")\n",
    "parser.add_argument(\"--lr\", type=float, default=0.0002, help=\"adam: learning rate\")\n",
    "parser.add_argument(\"--b1\", type=float, default=0.5, help=\"adam: decay of first order momentum of gradient\")\n",
    "parser.add_argument(\"--b2\", type=float, default=0.999, help=\"adam: decay of first order momentum of gradient\")\n",
    "parser.add_argument(\"--n_cpu\", type=int, default=8, help=\"number of cpu threads to use during batch generation\")\n",
    "parser.add_argument(\"--latent_dim\", type=int, default=100, help=\"dimensionality of the latent space\")\n",
    "parser.add_argument(\"--img_size\", type=int, default=28, help=\"size of each image dimension\")\n",
    "parser.add_argument(\"--channels\", type=int, default=1, help=\"number of image channels\")\n",
    "parser.add_argument(\"--n_critic\", type=int, default=5, help=\"number of training steps for discriminator per iter\")\n",
    "parser.add_argument(\"--clip_value\", type=float, default=0.01, help=\"lower and upper clip value for disc. weights\")\n",
    "parser.add_argument(\"--sample_interval\", type=int, default=400, help=\"interval betwen image samples\")\n",
    "parser.add_argument(\"--gpu_id\", type=int, default=2, help=\"gpu id\")\n",
    "\n",
    "sys.argv = 'main.py'\n",
    "sys.argv = sys.argv.split(' ')\n",
    "opt = parser.parse_args()\n",
    "print(opt)\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = str(opt.gpu_id)\n",
    "cuda = True if torch.cuda.is_available() else False\n",
    "\n",
    "img_shape = (opt.channels, opt.img_size, opt.img_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Generator, self).__init__()\n",
    "\n",
    "        def block(in_feat, out_feat, normalize=True):\n",
    "            layers = [nn.Linear(in_feat, out_feat)]\n",
    "            if normalize:\n",
    "                layers.append(nn.BatchNorm1d(out_feat, 0.8))\n",
    "            layers.append(nn.LeakyReLU(0.2, inplace=True))\n",
    "            return layers\n",
    "\n",
    "        self.model = nn.Sequential(\n",
    "            *block(opt.latent_dim, 128, normalize=False),\n",
    "            *block(128, 256),\n",
    "            *block(256, 512),\n",
    "            *block(512, 1024),\n",
    "            nn.Linear(1024, int(np.prod(img_shape))),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "    def forward(self, z):\n",
    "        img = self.model(z)\n",
    "        img = img.view(img.shape[0], *img_shape)\n",
    "        return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(int(np.prod(img_shape)), 512),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Linear(256, 1),\n",
    "        )\n",
    "\n",
    "    def forward(self, img):\n",
    "        img_flat = img.view(img.shape[0], -1)\n",
    "        validity = self.model(img_flat)\n",
    "        return validity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_gradient_penalty(D, real_samples, fake_samples):\n",
    "    \"\"\"Calculates the gradient penalty loss for WGAN GP\"\"\"\n",
    "    # Random weight term for interpolation between real and fake samples\n",
    "    alpha = Tensor(np.random.random((real_samples.size(0), 1, 1, 1)))\n",
    "    # Get random interpolation between real and fake samples\n",
    "    interpolates = (alpha * real_samples + ((1 - alpha) * fake_samples)).requires_grad_(True)\n",
    "    d_interpolates = D(interpolates)\n",
    "    fake = Variable(Tensor(real_samples.shape[0], 1).fill_(1.0), requires_grad=False)\n",
    "    # Get gradient w.r.t. interpolates\n",
    "    gradients = autograd.grad(\n",
    "        outputs=d_interpolates,\n",
    "        inputs=interpolates,\n",
    "        grad_outputs=fake,\n",
    "        create_graph=True,\n",
    "        retain_graph=True,\n",
    "        only_inputs=True,\n",
    "    )[0]\n",
    "    gradients = gradients.view(gradients.size(0), -1)\n",
    "    gradient_penalty = ((gradients.norm(2, dim=1) - 1) ** 2).mean()\n",
    "    return gradient_penalty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure data loader\n",
    "os.makedirs(\"../../data/mnist\", exist_ok=True)\n",
    "dataloader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST(\n",
    "        \"../../data/mnist\",\n",
    "        train=True,\n",
    "        download=True,\n",
    "        transform=transforms.Compose(\n",
    "            [transforms.Resize(opt.img_size), transforms.ToTensor(), transforms.Normalize([0.5], [0.5])]\n",
    "        ),\n",
    "    ),\n",
    "    batch_size=opt.batch_size,\n",
    "    shuffle=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss weight for gradient penalty\n",
    "lambda_gp = 10\n",
    "\n",
    "# Initialize generator and discriminator\n",
    "generator = Generator()\n",
    "discriminator = Discriminator()\n",
    "\n",
    "if cuda:\n",
    "    generator.cuda()\n",
    "    discriminator.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimizers\n",
    "optimizer_G = torch.optim.Adam(generator.parameters(), lr=opt.lr, betas=(opt.b1, opt.b2))\n",
    "optimizer_D = torch.optim.Adam(discriminator.parameters(), lr=opt.lr, betas=(opt.b1, opt.b2))\n",
    "\n",
    "Tensor = torch.cuda.FloatTensor if cuda else torch.FloatTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [*] No checkpoint!\n"
     ]
    }
   ],
   "source": [
    "ckpt_dir = './checkpoints' \n",
    "utils.mkdir(ckpt_dir)          \n",
    "try:\n",
    "    ckpt = utils.load_checkpoint(ckpt_dir)\n",
    "    start_epoch = ckpt['epoch']\n",
    "    discriminator.load_state_dict(ckpt['discriminator'])\n",
    "    generator.load_state_dict(ckpt['generator'])\n",
    "    optimizer_G.load_state_dict(ckpt['optimizer_D'])\n",
    "    optimizer_D.load_state_dict(ckpt['optimizer_G']) \n",
    "except:\n",
    "    print(' [*] No checkpoint!')\n",
    "    start_epoch = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(\"images\", exist_ok=True)\n",
    "writer = tensorboardX.SummaryWriter('./summaries')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0/200] [Batch 0/938] [D loss: 8.118450] [G loss: -0.061920]\n",
      "[Epoch 0/200] [Batch 400/938] [D loss: -1.222624] [G loss: -16.023088]\n",
      "[Epoch 0/200] [Batch 800/938] [D loss: -3.728967] [G loss: -2.206052]\n",
      "[Epoch 1/200] [Batch 260/938] [D loss: -7.337910] [G loss: 0.175825]\n",
      "[Epoch 1/200] [Batch 660/938] [D loss: -7.359250] [G loss: -2.500704]\n",
      "[Epoch 2/200] [Batch 120/938] [D loss: -7.440664] [G loss: -1.216056]\n",
      "[Epoch 2/200] [Batch 520/938] [D loss: -7.503472] [G loss: -2.644726]\n",
      "[Epoch 2/200] [Batch 920/938] [D loss: -6.824119] [G loss: -0.796952]\n",
      "[Epoch 3/200] [Batch 380/938] [D loss: -8.304548] [G loss: 7.043227]\n",
      "[Epoch 3/200] [Batch 780/938] [D loss: -8.992752] [G loss: 8.572596]\n",
      "[Epoch 4/200] [Batch 240/938] [D loss: -8.675409] [G loss: 5.611037]\n",
      "[Epoch 4/200] [Batch 640/938] [D loss: -8.103651] [G loss: 5.719254]\n",
      "[Epoch 5/200] [Batch 100/938] [D loss: -8.024593] [G loss: 2.871461]\n"
     ]
    }
   ],
   "source": [
    "batches_done = 0\n",
    "\n",
    "z_sample = Variable(Tensor(np.random.normal(0, 1, (25, opt.latent_dim))))\n",
    "\n",
    "for epoch in range(opt.n_epochs):\n",
    "    tdl = iter(dataloader)\n",
    "    for i, (imgs, targets) in enumerate(tdl):\n",
    "        \n",
    "        step = epoch * len(dataloader) + i + 1\n",
    "        \n",
    "        generator.train()\n",
    "\n",
    "        # Configure input\n",
    "        real_imgs = Variable(imgs.type(Tensor))\n",
    "\n",
    "        # ---------------------\n",
    "        #  Train Discriminator\n",
    "        # ---------------------\n",
    "\n",
    "        optimizer_D.zero_grad()\n",
    "\n",
    "        # Sample noise as generator input\n",
    "        z = Variable(Tensor(np.random.normal(0, 1, (imgs.shape[0], opt.latent_dim))))\n",
    "\n",
    "        # Generate a batch of images\n",
    "        fake_imgs = generator(z)\n",
    "\n",
    "        # Real images\n",
    "        real_validity = discriminator(real_imgs)\n",
    "        # Fake images\n",
    "        fake_validity = discriminator(fake_imgs)\n",
    "        # Gradient penalty\n",
    "        gradient_penalty = compute_gradient_penalty(discriminator, real_imgs.data, fake_imgs.data)\n",
    "        # Adversarial loss\n",
    "        wass_distance = torch.mean(real_validity) - torch.mean(fake_validity)\n",
    "        d_loss = -wass_distance + lambda_gp * gradient_penalty\n",
    "\n",
    "        d_loss.backward()\n",
    "        optimizer_D.step()\n",
    "        \n",
    "        writer.add_scalar('D/wd', wass_distance.item(), global_step=step)\n",
    "        writer.add_scalar('D/gp', gradient_penalty.item(), global_step=step)\n",
    "\n",
    "        # -----------------\n",
    "        #  Train Generator\n",
    "        # -----------------\n",
    "\n",
    "        optimizer_G.zero_grad()\n",
    "\n",
    "        # Train the generator every n_critic steps\n",
    "        if i % opt.n_critic == 0:\n",
    "\n",
    "            # Generate a batch of images\n",
    "            fake_imgs = generator(z)\n",
    "            # Loss measures generator's ability to fool the discriminator\n",
    "            # Train on fake images\n",
    "            fake_validity = discriminator(fake_imgs)\n",
    "            g_loss = -torch.mean(fake_validity)\n",
    "\n",
    "            g_loss.backward()\n",
    "            optimizer_G.step()\n",
    "            \n",
    "            writer.add_scalars('G',\n",
    "                               {\"g_loss\": g_loss.item()},\n",
    "                               global_step=step)\n",
    "\n",
    "            if batches_done % opt.sample_interval == 0:\n",
    "                print(\"[Epoch %d/%d] [Batch %d/%d] [D loss: %f] [G loss: %f]\"\n",
    "                    % (epoch, opt.n_epochs, i, len(dataloader), d_loss.item(), g_loss.item()))\n",
    "\n",
    "                #save_image(fake_imgs.data[:25], \"images/%d.png\" % batches_done, nrow=5, normalize=True)\n",
    "                generator.eval()\n",
    "                f_imgs_sample = generator(z_sample)\n",
    "                save_image(f_imgs_sample.data[:25], \"images/%d.png\" % batches_done, nrow=5, normalize=True)\n",
    "                \n",
    "            batches_done += opt.n_critic\n",
    "    \n",
    "    # checkpoint at epoch\n",
    "    utils.save_checkpoint({'epoch': epoch + 1,\n",
    "                           'discriminator': discriminator.state_dict(),\n",
    "                           'generator': generator.state_dict(),\n",
    "                           'optimizer_D': optimizer_D.state_dict(),\n",
    "                           'optimizer_G': optimizer_G.state_dict()},\n",
    "                          '%s/Epoch_(%d).ckpt' % (ckpt_dir, epoch + 1),\n",
    "                          max_keep=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
